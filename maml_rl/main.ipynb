{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAML():\n",
    "    def __init__(self, output_dir, meta_iter=200, train_batch_size=20, test_batch_size=40):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        \n",
    "        self.meta_iter = meta_iter\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.test_batch_size = test_batch_size\n",
    "        \n",
    "        self.history = []\n",
    "        self.train_loss = []\n",
    "        self.train_return = []\n",
    "        self.test_acc = []\n",
    "        \n",
    "        self.train_sampler = Sampler('RandomMiniEnv', meta_iter=meta_iter, \n",
    "                                     batch_size=train_batch_size, device=self.device)\n",
    "        self.test_sampler = Sampler('RandomMiniEnv', meta_iter=meta_iter,\n",
    "                                    batch_size=test_batch_size, device=self.device)\n",
    "        \n",
    "        self.policy = Policy()\n",
    "        self.baseline = LinearFeatureBaseline(input_size=135)\n",
    "        self.ml = MetaLearner(self.train_sampler, self.policy, \n",
    "                              self.baseline, num_episodes=train_batch_size, device=self.device)\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        self.checkpoint_path = os.path.join(output_dir, \n",
    "                                            \"checkpoint.pth.tar\")\n",
    "        self.config_path = os.path.join(output_dir, \"config.txt\")\n",
    "        \n",
    "        locs = {k : v for k, v in locals().items() if k is not 'self'}\n",
    "        self.__dict__.update(locs)\n",
    "        \n",
    "        if os.path.isfile(self.config_path):\n",
    "            with open(self.config_path, 'r') as f:\n",
    "                #if f.read()[:-1] != repr(self):\n",
    "                    print(f.read())\n",
    "                #    raise ValueError(\n",
    "                #        \"Cannot create this experiment: \"\n",
    "                #        \"I found a checkpoint conflicting with the current setting.\")\n",
    "            self.load()\n",
    "        else:\n",
    "            self.save()\n",
    "        \n",
    "    @property\n",
    "    def iteration(self):\n",
    "        return len(self.history)\n",
    "    \n",
    "    def setting(self):\n",
    "        return {'Policy' : self.policy,\n",
    "                'Baseline' : self.baseline,\n",
    "                'TrainBatchSize' : self.train_batch_size}  \n",
    "    \n",
    "    def __repr__(self):\n",
    "        string = ''\n",
    "        for key, val in self.setting().items():\n",
    "            string += '{}({})\\n'.format(key, val)\n",
    "        return string\n",
    "    \n",
    "    def state_dict(self):\n",
    "        return {'Policy' : self.policy.state_dict(),\n",
    "                'Baseline' : self.baseline.state_dict(),\n",
    "                'TrainSampler' : self.train_sampler,\n",
    "                'History' : self.history,\n",
    "                'TrainLoss' : self.train_loss,\n",
    "                'TrainReturn' : self.train_return}\n",
    "    \n",
    "    def load_state_dict(self, checkpoint):\n",
    "        self.policy.load_state_dict(checkpoint['Policy'])\n",
    "        self.baseline.load_state_dict(checkpoint['Baseline'])\n",
    "        \n",
    "        self.train_sampler = checkpoint['TrainSampler']\n",
    "        self.history = checkpoint['History']\n",
    "        self.train_loss = checkpoint['TrainLoss']\n",
    "        self.train_return = checkpoint['TrainReturn']\n",
    "        \n",
    "    def save(self):\n",
    "        torch.save(self.state_dict(), self.checkpoint_path)\n",
    "        with open(self.config_path, 'w') as f:\n",
    "            print(self, file=f)\n",
    "    \n",
    "    def load(self):\n",
    "        checkpoint = torch.load(self.checkpoint_path,\n",
    "                                map_location=self.device)\n",
    "        self.load_state_dict(checkpoint)\n",
    "        del checkpoint  \n",
    "        \n",
    "    def run(self):\n",
    "        start_iter = self.iteration\n",
    "        \n",
    "        print(\"Start/Continue training from iteration {}\".format(start_iter))\n",
    "        \n",
    "        for i in range(start_iter, self.meta_iter):\n",
    "            tasks = self.train_sampler.sample_tasks(low=1, \n",
    "                                                    high=10, \n",
    "                                                    num_tasks=10)\n",
    "            episodes = self.ml.sample(tasks, first_order=True)\n",
    "                        \n",
    "            avg_return = self.ml.average_return(episodes)\n",
    "            loss = self.ml.step(episodes)\n",
    "            \n",
    "            self.history.append(i)\n",
    "            self.train_return.append(avg_return)\n",
    "            self.train_loss.append(loss)\n",
    "            \n",
    "            self.save()\n",
    "            \n",
    "            print(\"Done with meta-iteration {}. Avg Return = {}, Loss = {}\".format(i,\n",
    "                                                                               avg_return,\n",
    "                                                                               loss))\n",
    "            \n",
    "        print(\"Finished training for {} meta-iterations\".format(self.meta_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy(Policy(\n",
      "  (fc1): Linear(in_features=135, out_features=100, bias=True)\n",
      "  (fc2): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (fc3): Linear(in_features=100, out_features=2, bias=True)\n",
      "  (tanh): Tanh()\n",
      "))\n",
      "Baseline(LinearFeatureBaseline(\n",
      "  (linear): Linear(in_features=274, out_features=1, bias=False)\n",
      "))\n",
      "TrainBatchSize(20)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exp = MAML(output_dir=\"experiment2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_episodes(task, policy, params):        \n",
    "    episodes = BatchEpisodes(batch_size=10, device=exp.device)\n",
    "\n",
    "    traj_id = 0\n",
    "\n",
    "    done = False\n",
    "    state = task.reset()\n",
    "\n",
    "    while not done:\n",
    "        with torch.no_grad():\n",
    "            action = policy(torch.Tensor(state).to(device=exp.device), \n",
    "                            params=params).sample()\n",
    "            action = action.cpu().numpy()\n",
    "\n",
    "        next_state, reward, done, _ = task.step(action)\n",
    "        episodes.append(next_state, action, reward, traj_id)\n",
    "\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            traj_id += 1\n",
    "\n",
    "            if traj_id == 10:\n",
    "                return episodes\n",
    "\n",
    "            done = False\n",
    "            state = task.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = exp.test_sampler.sample_tasks(low=1, high=10, num_tasks=1)[0]\n",
    "\n",
    "task_seed = 5\n",
    "task = exp.test_sampler.sample_tasks(low=task_seed, high=task_seed+1, num_tasks=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_episodes = [(0, create_episodes(task, exp.ml.policy, params=None), None)]\n",
    "\n",
    "for i in range(2):\n",
    "    _, episodes_prev, _ = test_episodes[-1]\n",
    "    \n",
    "    params = exp.ml.adapt(episodes_prev)\n",
    "    episodes_next = create_episodes(task, exp.ml.policy, params=params)\n",
    "    \n",
    "    test_episodes.append((i+1, episodes_next, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = test_episodes[-1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = task.reset()\n",
    "done = False\n",
    "\n",
    "task.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.5761158700615971\n",
      "-1.5406282942550993\n",
      "-1.5119582940422394\n",
      "-1.609404077613262\n",
      "-1.524193681834201\n",
      "-1.495800771470192\n",
      "-1.4435235987751454\n",
      "-1.427888525597278\n",
      "-1.3401237200003058\n",
      "-1.3591767113734505\n",
      "-1.342942467005984\n",
      "-1.2651055120510397\n",
      "-1.2250678635378864\n",
      "-1.1781794579282514\n",
      "-1.2008261828367142\n",
      "-1.1438650742836258\n",
      "-1.1046566978530075\n",
      "-1.061244558369876\n",
      "-1.0539644325755275\n",
      "-1.0328029744622813\n",
      "-1.0073963792124578\n",
      "-0.9961529588997886\n",
      "-0.9622234566230083\n",
      "-0.9854127232912243\n",
      "-0.9850130438222044\n",
      "-0.977671467998085\n",
      "-0.9668816221287406\n",
      "-0.9561388225984209\n",
      "-0.9489430021444315\n",
      "-0.9365147512592006\n",
      "-0.9188489395862028\n",
      "-0.9125948863019933\n",
      "-0.9089731505644062\n",
      "-0.8983341182960572\n",
      "-0.898221783772676\n",
      "-0.887583038598095\n",
      "-0.8813303350261429\n",
      "-0.8777090378390043\n",
      "-0.8644384746006922\n",
      "-0.8502908512010322\n",
      "-0.843160482856979\n",
      "-0.8395390090114423\n",
      "-0.832408555942688\n",
      "-0.8287872574770202\n",
      "-0.8286750217603922\n",
      "-0.8250543526127185\n",
      "-0.8214335466278041\n",
      "-0.8116724602506619\n",
      "-0.8089294048579105\n",
      "-0.805309606473951\n",
      "-0.7981808979060365\n",
      "-0.8007014060193478\n",
      "-0.797959669538761\n",
      "-0.7873233521596438\n",
      "-0.7740550283079134\n",
      "-0.7669274725253558\n",
      "-0.7633090205875736\n",
      "-0.7596906555589296\n",
      "-0.763089970925327\n",
      "-0.759472630872077\n",
      "-0.7567324742809214\n",
      "-0.7496061363390313\n",
      "-0.7433573152704166\n",
      "-0.7397401567401597\n",
      "-0.7396318406990033\n",
      "-0.736015269171652\n",
      "-0.7350310574087383\n",
      "-0.7156261671476457\n",
      "-0.7085018760041308\n",
      "-0.7083948904798646\n",
      "-0.7021484285778643\n",
      "-0.7020422503498136\n",
      "-0.7019364252347753\n",
      "-0.7018307805330913\n",
      "-0.7017256843220139\n",
      "-0.7016206834204256\n",
      "-0.6980072629617272\n",
      "-0.6943937383710902\n",
      "-0.6942891303502466\n",
      "-0.6941850690577482\n",
      "-0.6870641888537666\n",
      "-0.6869610921628158\n",
      "-0.6833494566437074\n",
      "-0.6832463618030498\n",
      "-0.6831435660281038\n",
      "-0.680409962501785\n",
      "-0.6803082498688033\n",
      "-0.6766981805414225\n",
      "-0.6765972305527996\n",
      "-0.6729880860287613\n",
      "-0.6728882012281782\n",
      "-0.672788959776223\n",
      "-0.6726899615555026\n",
      "-0.6664509852302715\n",
      "-0.6663528030352109\n",
      "-0.6662547788422192\n",
      "-0.6626482975509432\n",
      "-0.662551128302836\n",
      "-0.6624544898319488\n",
      "-0.6623581446013116\n",
      "-0.6622617400253443\n",
      "-0.6621658824557533\n",
      "-0.6594390369943766\n",
      "-0.6593440628711211\n",
      "-0.6592495277775643\n",
      "-0.659155348588024\n",
      "-0.6590617952475868\n",
      "-0.6589685800111503\n",
      "-0.658875785053572\n",
      "-0.6587833807817524\n",
      "-0.6586917887812347\n",
      "-0.6586004459601718\n",
      "-0.6585094728107727\n",
      "-0.658418964759861\n",
      "-0.6583291421061458\n",
      "-0.6582397480001414\n",
      "-0.6581508631899569\n",
      "-0.6580623104016705\n",
      "-0.6579742192551281\n",
      "-0.657886673126673\n",
      "-0.6577996925230465\n",
      "-0.6577132988786955\n",
      "-0.6576277143551963\n",
      "-0.657542716675364\n",
      "-0.657458416358448\n",
      "-0.6573748800554545\n",
      "-0.657291930676825\n",
      "-0.6572098188484827\n",
      "-0.6571281764012592\n",
      "-0.657047354390505\n",
      "-0.6569673415890742\n",
      "-0.6568881918691263\n",
      "-0.6568099383854947\n",
      "-0.6567320208015788\n",
      "-0.6566549084571041\n",
      "-0.6565787215209308\n",
      "-0.6565031054227286\n",
      "-0.65642838883372\n",
      "-0.6563546074069272\n",
      "-0.6562817705895172\n",
      "-0.6562097379625631\n",
      "-0.6561385212818782\n",
      "-0.6560682877810374\n",
      "-0.6559990346829785\n",
      "-0.6559307906533903\n",
      "-0.6558635409072968\n",
      "-0.6557972064848191\n",
      "-0.6557318722240875\n",
      "-0.6556675734271855\n",
      "-0.655604296937719\n",
      "-0.6555420473815381\n",
      "-0.6554808309709329\n",
      "-0.6554206540058659\n",
      "-0.655361522741997\n",
      "-0.6553034433889207\n",
      "-0.6552464220718424\n",
      "-0.6551904648794222\n",
      "-0.6551355778459292\n",
      "-0.6550817669499629\n",
      "-0.6550290380746714\n",
      "-0.6549773970623889\n",
      "-0.6549268497026054\n",
      "-0.6548774017121627\n",
      "-0.6548290587487213\n",
      "-0.6547818264008942\n",
      "-0.6547357088276564\n",
      "-0.6546907112473574\n",
      "-0.6546468391541106\n",
      "-0.6546040980017473\n",
      "-0.6545624931547294\n",
      "-0.6545220299490406\n",
      "-0.6544827120975204\n",
      "-0.6544445438746542\n",
      "-0.6544075304869814\n",
      "-0.6543716771972081\n",
      "-0.654336989230864\n",
      "-0.6543034717195415\n",
      "-0.6542711297507519\n",
      "-0.6542399683265466\n",
      "-0.6542099923868399\n",
      "-0.6541812067915675\n",
      "-0.6541536163337978\n",
      "-0.6541272257237686\n",
      "-0.6541020396126093\n",
      "-0.6540780625585342\n",
      "-0.654055350247314\n",
      "-0.6540338320690173\n",
      "-0.6540135669255054\n",
      "-0.6539945532557546\n",
      "-0.6539767125372347\n",
      "-0.6539600797823764\n",
      "-0.6539446824684646\n",
      "-0.653930559767085\n",
      "-0.653917635231293\n",
      "-0.6539059451982459\n",
      "-0.6538955002554749\n",
      "-0.6538863186501859\n",
      "-0.6538784163586617\n",
      "-0.6538717823647087\n",
      "-0.6538664185629092\n",
      "-0.653862319667851\n",
      "-0.6538595040809984\n",
      "-0.6538579689791479\n",
      "-0.653857726028666\n",
      "-0.6538587765119549\n",
      "-0.6538611250956973\n",
      "-0.6538647890397283\n",
      "-0.6538697772405243\n",
      "-0.6538760633632934\n",
      "-0.6538836551747269\n",
      "-0.6538925858272931\n",
      "-0.6539028106169088\n",
      "-0.6539144220146729\n",
      "-0.6539274000919777\n",
      "-0.6539416681880797\n",
      "-0.653957265325495\n",
      "-0.6539740534577274\n",
      "-0.6539921744842122\n",
      "-0.6540116484922851\n",
      "-0.6540323769053247\n",
      "-0.6540544142291336\n",
      "-0.6540777742496535\n",
      "-0.6541024129488285\n",
      "-0.6541283318033422\n",
      "-0.6541557383220934\n",
      "-0.65418443393063\n",
      "-0.6542144817940363\n",
      "-0.6542457923049825\n",
      "-0.6542783320410037\n",
      "-0.6543122445304353\n",
      "-0.6543474349044104\n",
      "-0.6543839736680943\n",
      "-0.657053538140283\n",
      "-0.6570927612690838\n",
      "-0.6571333146341659\n",
      "-0.6571751254772752\n",
      "-0.6572183980622461\n",
      "-0.6607717969535548\n",
      "-0.6608175570304435\n",
      "-0.6608646562221108\n",
      "-0.6609129631870801\n",
      "-0.6609626276491561\n",
      "-0.6636454801791757\n",
      "-0.6672065431426912\n",
      "-0.6672599288228244\n",
      "-0.6673146046595193\n",
      "-0.6770193913053567\n",
      "-0.6709355820494778\n",
      "-0.6762571788332301\n",
      "-0.6798254613651923\n",
      "-0.6798857633613782\n",
      "-0.6799468083489355\n",
      "-0.6835176912055276\n",
      "-0.6835808595607022\n",
      "-0.6836451332594593\n",
      "-0.690728289760456\n",
      "-0.6934265198310701\n",
      "-0.6934939550851141\n",
      "-0.7040889915548108\n",
      "-0.7111759019989545\n",
      "-0.6910713065596762\n",
      "-0.6911430928045585\n",
      "-0.7008649321993761\n",
      "-0.7079555468370872\n",
      "-0.7115383623405487\n",
      "-0.7116132540164157\n",
      "-0.7116890830731586\n",
      "-0.7117659398714249\n",
      "-0.7153527563295987\n",
      "-0.718062915845412\n",
      "-0.7216506729587397\n",
      "-0.7217304572608364\n",
      "-0.7288283737101373\n",
      "-0.7324184528169334\n",
      "-0.7517992830739191\n",
      "-0.7624087352305138\n",
      "-0.7624926164200742\n",
      "-0.7695962965425377\n",
      "-0.7758234469888865\n",
      "-0.782928003728277\n",
      "-0.7900335004543427\n",
      "-0.7936311324031585\n",
      "-0.8007382302229125\n",
      "-0.8078461203730433\n",
      "-0.814954163867469\n",
      "-0.8211855522669758\n",
      "-0.834435439161905\n",
      "-0.8345282853708379\n",
      "-0.8346218927028086\n",
      "-0.8487514501253637\n",
      "-0.8584956461875421\n",
      "-0.8691183697043382\n",
      "-0.8762321739658306\n",
      "-0.8868547063135154\n",
      "-0.8930915200636331\n",
      "-0.9028374973779087\n",
      "-0.9029350745998624\n",
      "-0.9126830584638761\n",
      "-0.9329578475006732\n",
      "-0.9400749241828409\n"
     ]
    }
   ],
   "source": [
    "r = 0\n",
    "which_one = 1\n",
    "\n",
    "while not done:\n",
    "    \n",
    "    if which_one == 1:\n",
    "        action = exp.ml.policy(torch.Tensor(state).to(exp.device), \n",
    "                              params=final_params)\n",
    "        action = action.loc.cpu().detach().numpy()\n",
    "\n",
    "        next_state, reward, done, _ = task.step(action)\n",
    "    else:\n",
    "        next_state, reward, done, _ = task.step(task.action_space.sample())\n",
    "    \n",
    "    r += reward\n",
    "    \n",
    "    print(reward)\n",
    "        \n",
    "    task.render()\n",
    "    \n",
    "    state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
